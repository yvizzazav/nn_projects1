{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from os import listdir\nfrom numpy import asarray\nfrom numpy import vstack\nfrom numpy import savez_compressed\nfrom numpy import load\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy.random import randint\nfrom tensorflow.keras.optimizers import Adam\nfrom keras.initializers import RandomNormal\nfrom keras.models import Model\nfrom keras import Input\nfrom keras.layers import Conv2D,Conv3D\nfrom keras.layers import Conv2DTranspose, Conv3DTranspose\nfrom keras.layers import LeakyReLU\nfrom keras.layers import Activation\nfrom keras.layers import Concatenate\nfrom keras.layers import Dropout\nfrom keras.layers import BatchNormalization\nfrom keras.layers import LeakyReLU\ndef load_images(path,size=(256,512)):\n    src_list, tar_list=list(),list()\n    for filename in listdir(path):\n        pixels=load_img(path+filename,target_size=size)\n        pixels=img_to_array(pixels)\n        sat_img,map_img=pixels[:,:256],pixels[:,256:]\n        src_list.append(sat_img)\n        tar_list.append(map_img)\n    return [asarray(src_list),asarray(tar_list)]","metadata":{"execution":{"iopub.status.busy":"2023-09-28T12:57:49.771416Z","iopub.execute_input":"2023-09-28T12:57:49.772185Z","iopub.status.idle":"2023-09-28T12:58:00.585262Z","shell.execute_reply.started":"2023-09-28T12:57:49.772147Z","shell.execute_reply":"2023-09-28T12:58:00.583985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from numpy import load\nimport numpy as np\nfrom matplotlib import pyplot\nimport tensorflow as tf\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ntar_images_temp = np.load('../input/imagestranslation/images7256.txt.npy')\ntar_images= (tar_images_temp / 127.5) - 1.0\nsrc_images_temp = np.load('../input/imagestranslation/generated256.npy')\nsrc_images = (src_images_temp * 2.0) - 1.0\nprint('Loaded: ',src_images.shape,tar_images.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:26:38.913629Z","iopub.execute_input":"2023-09-28T13:26:38.914173Z","iopub.status.idle":"2023-09-28T13:26:41.485993Z","shell.execute_reply.started":"2023-09-28T13:26:38.914132Z","shell.execute_reply":"2023-09-28T13:26:41.485176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(src_images_temp[1])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:42:10.802820Z","iopub.execute_input":"2023-09-28T13:42:10.803318Z","iopub.status.idle":"2023-09-28T13:42:11.177304Z","shell.execute_reply.started":"2023-09-28T13:42:10.803275Z","shell.execute_reply":"2023-09-28T13:42:11.175818Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nplt.imshow(tar_images_temp[1])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:41:26.815284Z","iopub.execute_input":"2023-09-28T13:41:26.815863Z","iopub.status.idle":"2023-09-28T13:41:27.168468Z","shell.execute_reply.started":"2023-09-28T13:41:26.815816Z","shell.execute_reply":"2023-09-28T13:41:27.167090Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\ndef define_discriminator(image_shape):\n    init = RandomNormal(stddev=0.02)\n    in_src_image = Input(shape=image_shape)\n # target image input\n    in_target_image = Input(shape=image_shape)\n # concatenate images channel-wise\n    merged = Concatenate()([in_src_image, in_target_image])\n    d = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(merged)\n    d = LeakyReLU(alpha=0.2)(d)\n    d = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n # C256\n    d = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n # C512\n    d = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n # second last output layer\n    d = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n    d = BatchNormalization()(d)\n    d = LeakyReLU(alpha=0.2)(d)\n # patch output\n    d = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n    patch_out = Activation('sigmoid')(d)\n # define model\n    model = Model([in_src_image, in_target_image], patch_out)\n # compile model\n    opt = Adam(lr=0.0002, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt, loss_weights=[0.5])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:43:06.789408Z","iopub.execute_input":"2023-09-28T13:43:06.789878Z","iopub.status.idle":"2023-09-28T13:43:06.805461Z","shell.execute_reply.started":"2023-09-28T13:43:06.789841Z","shell.execute_reply":"2023-09-28T13:43:06.803999Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_encoder_block(layer_in, n_filters, batchnorm=True):\n    init = RandomNormal(stddev=0.02)\n # add downsampling layer\n    g = Conv2D(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n # conditionally add batch normalization\n    if batchnorm:\n        g = BatchNormalization()(g, training=True)\n # leaky relu activation\n    g = LeakyReLU(alpha=0.2)(g)\n    return g\n \n# define a decoder block\ndef decoder_block(layer_in, skip_in, n_filters, dropout=True):\n    init = RandomNormal(stddev=0.02)\n # add upsampling layer\n    g = Conv2DTranspose(n_filters, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(layer_in)\n # add batch normalization\n    g = BatchNormalization()(g, training=True)\n # conditionally add dropout\n    if dropout:\n        g = Dropout(0.5)(g, training=True)\n # merge with skip connection\n    g = Concatenate()([g, skip_in])\n # relu activation\n    g = Activation('relu')(g)\n    return g","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:43:13.614779Z","iopub.execute_input":"2023-09-28T13:43:13.616264Z","iopub.status.idle":"2023-09-28T13:43:13.627750Z","shell.execute_reply.started":"2023-09-28T13:43:13.616206Z","shell.execute_reply":"2023-09-28T13:43:13.626681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_generator(image_shape=(256,256,3)):\n    init = RandomNormal(stddev=0.02)\n # image input\n    in_image = Input(shape=image_shape)\n # encoder model\n    e1 = define_encoder_block(in_image, 64, batchnorm=False)\n    e2 = define_encoder_block(e1, 128)\n    e3 = define_encoder_block(e2, 256)\n    e4 = define_encoder_block(e3, 512)\n    e5 = define_encoder_block(e4, 512)\n    e6 = define_encoder_block(e5, 512)\n    e7 = define_encoder_block(e6, 512)\n # bottleneck, no batch norm and relu\n    b = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(e7)\n    b = Activation('relu')(b)\n # decoder model\n    d1 = decoder_block(b, e7, 512)\n    d2 = decoder_block(d1, e6, 512)\n    d3 = decoder_block(d2, e5, 512)\n    d4 = decoder_block(d3, e4, 512, dropout=False)\n    d5 = decoder_block(d4, e3, 256, dropout=False)\n    d6 = decoder_block(d5, e2, 128, dropout=False)\n    d7 = decoder_block(d6, e1, 64, dropout=False)\n # output\n    g = Conv2DTranspose(3, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d7)\n    out_image = Activation('tanh')(g)\n # define model\n    model = Model(in_image, out_image)\n    return model ","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:43:41.399072Z","iopub.execute_input":"2023-09-28T13:43:41.399640Z","iopub.status.idle":"2023-09-28T13:43:41.413241Z","shell.execute_reply.started":"2023-09-28T13:43:41.399589Z","shell.execute_reply":"2023-09-28T13:43:41.411851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def define_gan(g_model, d_model, image_shape):\n # make weights in the discriminator not trainable\n    for layer in d_model.layers:\n        if not isinstance(layer, BatchNormalization):\n            layer.trainable = False\n            # define the source image\n            in_src = Input(shape=image_shape)\n            # connect the source image to the generator input\n            gen_out = g_model(in_src)\n            # connect the source input and generator output to the discriminator input\n            dis_out = d_model([in_src, gen_out])\n            # src image as input, generated image and classification output\n            model = Model(in_src, [dis_out, gen_out])\n            # compile model\n            opt = Adam(lr=0.0002, beta_1=0.5)\n            model.compile(loss=['binary_crossentropy', 'mae'], optimizer=opt, loss_weights=[1,100])\n    return model","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:43:51.333411Z","iopub.execute_input":"2023-09-28T13:43:51.333884Z","iopub.status.idle":"2023-09-28T13:43:51.343279Z","shell.execute_reply.started":"2023-09-28T13:43:51.333847Z","shell.execute_reply":"2023-09-28T13:43:51.342162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def load_real_samples(filename):\n    data=load(filename)\n    X1,X2=data['arr_0'], data['arr_1']\n    X1=(X1-127.5)/127.5\n    X2=(X2-127.5)/127.5\n    return [X1,X2]  \n# select a batch of random samples, returns images and target\ndef generate_real_samples(dataset, n_samples, patch_shape):\n    trainA, trainB = dataset\n # choose random instances\n    ix = randint(0, trainA.shape[0], n_samples)\n # retrieve selected images\n    X1, X2 = trainA[ix], trainB[ix]\n # generate 'real' class labels (1)\n    y = ones((n_samples, patch_shape, patch_shape, 1))\n    return [X1, X2], y\ndef generate_fake_samples(g_model, samples, patch_shape):\n    X = g_model.predict(samples)\n # create 'fake' class labels (0)\n    y = zeros((len(X), patch_shape, patch_shape, 1))\n    return X, y\n","metadata":{"execution":{"iopub.status.busy":"2023-08-19T16:48:41.444293Z","iopub.execute_input":"2023-08-19T16:48:41.444610Z","iopub.status.idle":"2023-08-19T16:48:41.452150Z","shell.execute_reply.started":"2023-08-19T16:48:41.444588Z","shell.execute_reply":"2023-08-19T16:48:41.451149Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from matplotlib import pyplot\ndef summarize_performance(step, g_model, d_model,trainA,trainB,n_samples=3):\n    [X_realA, X_realB], _ = generate_real_samples([trainA,trainB], n_samples, 1)\n    X_fakeB, _ = generate_fake_samples(g_model, X_realA, 1)\n    X_realA = (X_realA + 1) / 2.0\n    X_realB = (X_realB + 1) / 2.0\n    X_fakeB = (X_fakeB + 1) / 2.0\n    for i in range(n_samples):\n        pyplot.subplot(3, n_samples, 1 + i)\n        pyplot.axis('off')\n        pyplot.imshow(X_realA[i])\n    for i in range(n_samples):\n        pyplot.subplot(3, n_samples, 1 + n_samples + i)\n        pyplot.axis('off')\n        pyplot.imshow(X_fakeB[i])\n    for i in range(n_samples):\n        pyplot.subplot(3, n_samples, 1 + n_samples*2 + i)\n        pyplot.axis('off')\n        pyplot.imshow(X_realB[i])\n    filename1 = 'plot_%06d.png' % (step+1)\n    pyplot.savefig(filename1)\n    pyplot.close()\n    filename2 = 'gmodel.h5' \n    g_model.save(filename2)\n    filename3 = 'dmodel.h5'\n    d_model.save(filename3)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:44:24.663484Z","iopub.execute_input":"2023-09-28T13:44:24.663969Z","iopub.status.idle":"2023-09-28T13:44:24.677633Z","shell.execute_reply.started":"2023-09-28T13:44:24.663933Z","shell.execute_reply":"2023-09-28T13:44:24.676429Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def train(d_model, g_model, gan_model, trainA,trainB, n_epochs=15, n_batch=1):\n    n_patch=d_model.output_shape[1]\n    bat_per_epo=int(len(trainA)/n_batch)\n    n_steps=bat_per_epo*n_epochs\n    for i in range(n_steps):\n        [X_realA,X_realB],y_real=generate_real_samples([trainA,trainB],n_batch,n_patch)\n        X_fakeB,y_fake=generate_fake_samples(g_model,X_realA,n_patch)\n        d_loss1=d_model.train_on_batch([X_realA,X_realB],y_real)\n        d_loss2=d_model.train_on_batch([X_realA,X_fakeB],y_fake)\n        g_loss,_,_=gan_model.train_on_batch(X_realA,[y_real,X_realB])\n        print('>%d, d1[%.3f] d2[%.3f] g[%.3f]' % (i+1,d_loss1,d_loss2,g_loss))\n        if(i+1)%(bat_per_epo*1)==0:\n            summarize_performance(i,g_model,d_model, trainA,trainB)      ","metadata":{"execution":{"iopub.status.busy":"2023-08-19T16:48:49.105941Z","iopub.execute_input":"2023-08-19T16:48:49.106269Z","iopub.status.idle":"2023-08-19T16:48:49.113630Z","shell.execute_reply.started":"2023-08-19T16:48:49.106241Z","shell.execute_reply":"2023-08-19T16:48:49.112646Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nstrategy = tf.distribute.MirroredStrategy()","metadata":{"execution":{"iopub.status.busy":"2023-08-16T17:45:53.419241Z","iopub.execute_input":"2023-08-16T17:45:53.419765Z","iopub.status.idle":"2023-08-16T17:45:53.558713Z","shell.execute_reply.started":"2023-08-16T17:45:53.419716Z","shell.execute_reply":"2023-08-16T17:45:53.557685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n#with strategy.scope():\nimage_shape=(256,256,3)\n    #d_model = define_discriminator(image_shape)\n    #g_model = define_generator(image_shape)\nd_model = load_model('../input/modelstranslation/dmodel16.h5')\ng_model = load_model('../input/modelstranslation/gmodel16.h5')\ngan_model = define_gan(g_model, d_model, image_shape)\ntrain(d_model, g_model, gan_model, src_images,tar_images)","metadata":{"execution":{"iopub.status.busy":"2023-08-23T16:05:20.318243Z","iopub.execute_input":"2023-08-23T16:05:20.318703Z","iopub.status.idle":"2023-08-23T16:05:28.267107Z","shell.execute_reply.started":"2023-08-23T16:05:20.318670Z","shell.execute_reply":"2023-08-23T16:05:28.264807Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images = np.load('../input/modelstranslation/resultstest.npy')\nprint(test_images.shape)\ntar_images_test2 = np.load('../input/rendering7/imagestest.txt.npy')\nindexes_to_remove = [11, 13,18,43,45,52,75]\ntar_images_test2= np.delete(tar_images_test2, indexes_to_remove, axis=0)\nprint(tar_images_test2.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:09:20.549090Z","iopub.execute_input":"2023-09-28T14:09:20.549589Z","iopub.status.idle":"2023-09-28T14:09:20.571979Z","shell.execute_reply.started":"2023-09-28T14:09:20.549550Z","shell.execute_reply":"2023-09-28T14:09:20.570262Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.models import load_model\nfrom numpy import vstack\nmodel1 = load_model('../input/modelstranslation/gmodel18.h5')\nmodel2 = load_model('../input/modelstranslation/dmodel18.h5')\ntest_images2=[]\nfor old_image in test_images:\n    new_image = np.ones((256, 256, 3))\n    start_x = (256 - 64) // 2\n    start_y = (256 - 64) // 2\n    new_image[start_y:start_y+64, start_x:start_x+64, :] = old_image\n    test_images2.append(new_image)\ntest_images2=np.array(test_images2)\nprint(test_images2.shape)\ntest_images2 = (test_images2 * 2.0) - 1.0\nindexes_to_remove = [11, 13,18,43,45,52,75]#bad data\ntest_images2= np.delete(test_images2, indexes_to_remove, axis=0)\ngen_images = model1.predict(test_images2)\nprint(gen_images.shape)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:35:18.500730Z","iopub.execute_input":"2023-09-28T14:35:18.501367Z","iopub.status.idle":"2023-09-28T14:35:41.479970Z","shell.execute_reply.started":"2023-09-28T14:35:18.501318Z","shell.execute_reply":"2023-09-28T14:35:41.478530Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.utils import plot_model\nfrom graphviz import Source\nimport pydot\nfrom graphviz import Digraph\nfrom keras.models import load_model\nplot_model(model2, to_file='model2.png', show_shapes=True, show_layer_names=True, rankdir='TB')","metadata":{"execution":{"iopub.status.busy":"2023-09-28T13:51:20.880909Z","iopub.execute_input":"2023-09-28T13:51:20.882024Z","iopub.status.idle":"2023-09-28T13:51:21.391585Z","shell.execute_reply.started":"2023-09-28T13:51:20.881975Z","shell.execute_reply":"2023-09-28T13:51:21.390648Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"gen_images=(gen_images+1)/2.0\ntest_images2=(test_images2+1)/2.0","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:37:57.476879Z","iopub.execute_input":"2023-09-28T14:37:57.477404Z","iopub.status.idle":"2023-09-28T14:37:57.578458Z","shell.execute_reply.started":"2023-09-28T14:37:57.477360Z","shell.execute_reply":"2023-09-28T14:37:57.577423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(64, 64))\naxes[0].imshow(test_images2[50])\naxes[1].imshow(gen_images[50])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:38:29.306795Z","iopub.execute_input":"2023-09-28T14:38:29.307390Z","iopub.status.idle":"2023-09-28T14:38:32.748773Z","shell.execute_reply.started":"2023-09-28T14:38:29.307341Z","shell.execute_reply":"2023-09-28T14:38:32.747334Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(64, 64))\naxes[0].imshow(test_images2[10])\naxes[1].imshow(gen_images[10])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:50:47.933561Z","iopub.execute_input":"2023-09-28T14:50:47.934112Z","iopub.status.idle":"2023-09-28T14:50:51.186807Z","shell.execute_reply.started":"2023-09-28T14:50:47.934063Z","shell.execute_reply":"2023-09-28T14:50:51.185602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(64, 64))\naxes[0].imshow(test_images2[20])\naxes[1].imshow(gen_images[20])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:51:07.443612Z","iopub.execute_input":"2023-09-28T14:51:07.444318Z","iopub.status.idle":"2023-09-28T14:51:10.738605Z","shell.execute_reply.started":"2023-09-28T14:51:07.444249Z","shell.execute_reply":"2023-09-28T14:51:10.737273Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(64, 64))\naxes[0].imshow(test_images2[40])\naxes[1].imshow(gen_images[40])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:52:18.366309Z","iopub.execute_input":"2023-09-28T14:52:18.366878Z","iopub.status.idle":"2023-09-28T14:52:21.657019Z","shell.execute_reply.started":"2023-09-28T14:52:18.366825Z","shell.execute_reply":"2023-09-28T14:52:21.655725Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(64, 64))\naxes[0].imshow(test_images2[70])\naxes[1].imshow(gen_images[70])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:54:07.058632Z","iopub.execute_input":"2023-09-28T14:54:07.059068Z","iopub.status.idle":"2023-09-28T14:54:10.377895Z","shell.execute_reply.started":"2023-09-28T14:54:07.059020Z","shell.execute_reply":"2023-09-28T14:54:10.376719Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig, axes = plt.subplots(1, 2, figsize=(64, 64))\naxes[0].imshow(test_images2[65])\naxes[1].imshow(gen_images[65])","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:55:53.428894Z","iopub.execute_input":"2023-09-28T14:55:53.429392Z","iopub.status.idle":"2023-09-28T14:55:56.914504Z","shell.execute_reply.started":"2023-09-28T14:55:53.429355Z","shell.execute_reply":"2023-09-28T14:55:56.913465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from skimage.transform import resize\nresized_images = np.zeros((77, 64, 64, 3), dtype=np.float32)\n# Loop through each image and resize using bilinear interpolation\nfor i in range(77):\n    resized_images[i] = resize(gen_images[i], (64, 64, 3), mode='constant', preserve_range=True)","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:40:46.615839Z","iopub.execute_input":"2023-09-28T14:40:46.617433Z","iopub.status.idle":"2023-09-28T14:40:47.459570Z","shell.execute_reply.started":"2023-09-28T14:40:46.617385Z","shell.execute_reply":"2023-09-28T14:40:47.458231Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_rows = 2\nnum_cols = 5\nimport matplotlib.pyplot as plt\n# Loop through the images and create the grid\nfor i,item in enumerate([0,2,3,4,25]):\n    plt.subplot(num_rows, num_cols, i+1)\n    plt.axis('off')\n    plt.imshow(resized_images[item])\n    plt.title('Згенероване')\n\nfor i,item in enumerate([0,2,3,4,25]):\n    plt.subplot(num_rows, num_cols, i+6)  # Move to the second row\n    plt.axis('off')\n    plt.imshow(tar_images_test2[item])\n    plt.title('Справжнє')\n\nplt.tight_layout()  # Adjust layout spacing\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:42:34.018278Z","iopub.execute_input":"2023-09-28T14:42:34.018758Z","iopub.status.idle":"2023-09-28T14:42:34.908323Z","shell.execute_reply.started":"2023-09-28T14:42:34.018722Z","shell.execute_reply":"2023-09-28T14:42:34.906874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport math\nfrom sklearn.metrics import mean_squared_error\nfrom skimage import io, color\nfrom skimage.metrics import structural_similarity as compare_ssim\ns_values = []\nfirst_array=resized_images\nsecond_array=tar_images_test2\nsecond_array = second_array.astype(np.float32) / 255.0\n# Loop through the images and calculate MSE for corresponding pairs\nfor i in range(len(first_array)):\n    s1 = compare_ssim(second_array[i,:,:,0],first_array[i,:,:,0], data_range=1)\n    s2 = compare_ssim(second_array[i,:,:,1],first_array[i,:,:,1], data_range=1)\n    s3 = compare_ssim(second_array[i,:,:,2],first_array[i,:,:,2], data_range=1)\n    s=(s1+s2+s3)/3.0\n    s_values.append(s)\n\n# Calculate the average MSE\naverage_s = np.mean(s_values)\nprint(average_s)\nintervals2 = [(0, 0.001), (0.001, 0.002), (0.002, 0.003), (0.003, 0.004), (0.004, 0.005), (0.005, 0.006),(0.006,0.1)]\nintervals3 = [(0, 0.6), (0.6, 0.73), (0.73, 0.82),(0.82,0.93),(0.93,1)]\nintervals = [(0, 0.55), (0.55, 0.75), (0.75, 0.85),(0.85,0.93),(0.93,1)]\ninterval_counts = [0] * len(intervals)\n\nfor s in s_values:\n    for i, interval in enumerate(intervals):\n        lower_bound, upper_bound = interval\n        if lower_bound <= s < upper_bound:\n            interval_counts[i] += 1\n\ntotal_values = len(s_values)\npercentages = [(count / total_values) * 100 for count in interval_counts]\n\n# Print percentages for each interval\nfor i, interval in enumerate(intervals):\n    print(f\"Percentage of values in interval {interval}: {percentages[i]:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2023-09-28T14:46:02.565070Z","iopub.execute_input":"2023-09-28T14:46:02.565597Z","iopub.status.idle":"2023-09-28T14:46:03.203290Z","shell.execute_reply.started":"2023-09-28T14:46:02.565559Z","shell.execute_reply":"2023-09-28T14:46:03.201669Z"},"trusted":true},"execution_count":null,"outputs":[]}]}